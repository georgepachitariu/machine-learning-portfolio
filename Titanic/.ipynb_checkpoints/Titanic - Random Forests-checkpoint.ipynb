{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Titanic: Machine Learning from Disaster\n",
    "\n",
    "### To predict the survival of the passengers\n",
    "\n",
    "This script uses a dataset that was taken from kaggle.com from the competition [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic/data) :\n",
    "\n",
    "\n",
    "Variable descriptions of the data:\n",
    "\n",
    "| Column      | Description  |\n",
    "|-------------|---|\n",
    "|  survival   | Survival (0 = No; 1 = Yes)  |\n",
    "|  pclass     |  Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)|\n",
    "|  name       |  Name |\n",
    "|  sex        |  Sex |\n",
    "|  age        |  Age |\n",
    "|  sibsp      | Number of Siblings/Spouses Aboard  |\n",
    "|  parch      | Number of Parents/Children Aboard  |\n",
    "|  ticket     | Ticket Number  |\n",
    "|  fare       | Passenger Fare  |\n",
    "|  cabin      |  Cabin  |\n",
    "|  embarked   | Port of Embarkation (C=Cherbourg; Q=Queenstown; S=Southampton)|\n",
    "\n",
    "Special notes:     \n",
    "\n",
    "**Pclass** is a proxy for socio-economic status (SES) :\n",
    " * 1st ~ Upper; \n",
    " * 2nd ~ Middle; \n",
    " * 3rd ~ Lower\n",
    "\n",
    "**Age** is in Years; Fractional if Age less than One (1). If the Age is Estimated, it is in the form xx.5\n",
    "\n",
    "With respect to the family relation variables (i.e. sibsp and parch) some relations were ignored.  The following are the definitions used for sibsp and parch.\n",
    "\n",
    "**Sibling**:  Brother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic\n",
    "\n",
    "**Spouse**:   Husband or Wife of Passenger Aboard Titanic (Mistresses and Fiances Ignored)\n",
    "\n",
    "**Parent**:   Mother or Father of Passenger Aboard Titanic\n",
    "\n",
    "**Child**:    Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic\n",
    "\n",
    "Other family relatives excluded from this study include cousins, nephews/nieces, aunts/uncles, and in-laws.  Some children travelled only with a nanny, therefore parch=0 for them.  As well, some travelled with very close friends or neighbors in a village, however, the definitions do not support such relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File Titanic/train.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ad5f7f9d6b53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Titanic/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Titanic/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3427)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6861)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File Titanic/train.csv does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data=pd.read_csv('train.csv')\n",
    "test_data=pd.read_csv('test.csv')\n",
    "\n",
    "train_data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Filling the values that are not available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "def my_fillna(df):\n",
    "    df['Cabin']=df['Cabin'].fillna('/')\n",
    "    \n",
    "    # 2 cases\n",
    "    df['Embarked']=df['Embarked'].fillna('/')\n",
    "    \n",
    "    # it's only one case\n",
    "    df['Fare']=df['Fare'].fillna( df['Fare'].median() )\n",
    "    \n",
    "    df['Parch']=df['Parch'].fillna( 0 )\n",
    "    df['SibSp']=df['SibSp'].fillna( 0 )\n",
    "    \n",
    "my_fillna(train_data)    \n",
    "my_fillna(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Splitting complex columns to separate different information\n",
    "\n",
    "For example, I can split the column **Cabin** (ex 'C85') into 'Cabin letter' -which is the deck- ('C') and the 'Room number' ('85')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getCabinNumber(s):\n",
    "    x= s.split(' ')[0][1:]\n",
    "    if(len(x) ==0):\n",
    "        return 0\n",
    "    else:\n",
    "        return int(x)\n",
    "\n",
    "def getFirstChar(s):\n",
    "    return s[0] if(len(s)>0) else '/'\n",
    "\n",
    "def splitColumns(df):    \n",
    "    df['CabinLetter']=df['Cabin'].apply(lambda s: getFirstChar(s))\n",
    "    df['CabinNumber']=df['Cabin'].apply(lambda x: getCabinNumber(x))\n",
    "    # there can be multiple cabins under a single name\n",
    "    # TODO find better ways of extracting features\n",
    "    df['NrCabins']=df['Cabin'].apply(lambda x: 0 if(x=='/') else len(x.split(' ')))\n",
    "    \n",
    "    df['Apelative']=df['Name'].apply(lambda x : x.split(' ')[1])\n",
    "    df['LastName']=df['Name'].apply(lambda x : x.split(',')[0])    \n",
    "    df['FirstName']=df['Name'].apply(lambda x : x.split(' ')[2])\n",
    "    \n",
    "    df['TicketSeria']=df['Ticket'].apply(lambda x: \n",
    "                                         hash(x.split(' ')[0]) if(' ' in x) else -1)\n",
    "    \n",
    "splitColumns(train_data)\n",
    "splitColumns(test_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Converting strings to numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getSex(s):\n",
    "    if(s == \"male\"): return 1\n",
    "    else:\n",
    "        if(s == \"female\"): return 0\n",
    "        else: return 2 #unknown\n",
    "\n",
    "def convertData(df):\n",
    "    df['CabinLetter']=hash(df['CabinLetter'].to_string())\n",
    "    #df['CabinNumber']=ord(df['CabinNumber'][0])\n",
    "    df['Apelative']=hash(df['Apelative'].to_string())\n",
    "    df['LastName']=hash(df['LastName'].to_string())    \n",
    "    df['FirstName']=hash(df['FirstName'].to_string())\n",
    "    df['Embarked']=hash(df['Embarked'].to_string())\n",
    "    df['Sex']=df['Sex'].apply(lambda s: getSex(s))\n",
    "\n",
    "convertData(train_data)\n",
    "convertData(test_data)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inferring Age column\n",
    "\n",
    "A lot of age values are missing (177 from 891 values). Since age is an important feature for determining the fate of a passenger (children and women had priority for the rescue boats) I will try to predict ages missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def getAllAgeFeatures(df):\n",
    "    return df[['Parch', 'SibSp']]\n",
    "    \n",
    "# ~700 rows\n",
    "labeled_data = train_data[ train_data['Age'].notnull() ]\n",
    "\n",
    "nr=10    \n",
    "rf_sum=0\n",
    "mean_sum=0\n",
    "kf = KFold(n_splits=nr)\n",
    "for train_index, test_index in kf.split(labeled_data):\n",
    "\n",
    "    x_train=getAllAgeFeatures(labeled_data.iloc[train_index])\n",
    "    x_test=getAllAgeFeatures(labeled_data.iloc[test_index])\n",
    "  \n",
    "    y_train=labeled_data.iloc[train_index]['Age']\n",
    "    y_test=labeled_data.iloc[test_index]['Age']\n",
    "    \n",
    "    model = RandomForestRegressor().fit(x_train, y_train)\n",
    "    \n",
    "    predicted_age=model.predict(x_test)\n",
    "    rf_sum=rf_sum + ((predicted_age - y_test)**2).sum()\n",
    "    \n",
    "    mean=labeled_data.iloc[train_index]['Age'].mean()\n",
    "    mean_sum=mean_sum + ((mean - y_test)**2).sum()\n",
    "\n",
    "    \n",
    "print 'Cost function is Least-Squares'     \n",
    "print 'Using random forest gressor: '+str(rf_sum/nr)    \n",
    "print 'Using the mean value: '+str(mean_sum/nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_age(df):\n",
    "    \n",
    "    labeled_data = df[ df['Age'].notnull() ]    \n",
    "    \n",
    "    unlabeled_i=df['Age'].isnull()\n",
    "    unlabeled_data = df[ unlabeled_i ]\n",
    "    \n",
    "    x_train=getAllAgeFeatures(labeled_data)\n",
    "    y_train=labeled_data['Age']\n",
    "\n",
    "    model = RandomForestRegressor().fit(x_train, y_train)\n",
    "\n",
    "    df.loc[unlabeled_i, 'Age']=model.predict(getAllAgeFeatures(unlabeled_data))\n",
    "    \n",
    "predict_age(train_data)\n",
    "predict_age(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def get_features():\n",
    "    return [\"Pclass\", \"Fare\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"NrCabins\",\"CabinLetter\"]\n",
    "    \n",
    "def get_df_features(df):\n",
    "    return df[get_features()].as_matrix()\n",
    "    \n",
    "def train_model(X, y):\n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc = rfc.fit(X, y)\n",
    "    #print sorted(zip(map(lambda x: round(x, 4), clf.feature_importances_), get_features()), \n",
    "    #         reverse=True)\n",
    "    return rfc\n",
    "    \n",
    "\n",
    "X=get_df_features(train_data)\n",
    "y=train_data['Survived']\n",
    "\n",
    "nr=10\n",
    "cost=0\n",
    "cost_2=0\n",
    "kf = KFold(n_splits=nr)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    \n",
    "    model=train_model(X[train_index], y[train_index])\n",
    "    \n",
    "    predicted=model.predict(X[test_index])    \n",
    "    cost=cost+((predicted - y[test_index])**2).sum()    \n",
    "    \n",
    "print 'Using random forest: successful_predictions/nr_cases: '\n",
    "print str( (len(X) - cost)  / (float)(len(X)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train using all the labeled data\n",
    "model = train_model(X, y) \n",
    "\n",
    "output=DataFrame()\n",
    "output['PassengerId']=test_data['PassengerId']\n",
    "output['Survived']=model.predict(get_df_features(test_data))\n",
    "\n",
    "\n",
    "output[['PassengerId', 'Survived']].to_csv(path_or_buf='predictions.csv', header=True, index=False)\n",
    "print 'Done.'"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
