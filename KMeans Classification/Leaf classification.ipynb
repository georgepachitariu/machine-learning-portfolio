{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Leaf classification using unsupervised learning \n",
    "## KMeans clustering\n",
    "\n",
    "The data has a labeled training set and a testing set. \n",
    "**I will not use the labels in training, but only in scoring the trained model.**\n",
    "\n",
    "There are 99 species of leaves. \n",
    "There will be 1 cluster for each species.\n",
    " \n",
    "## Data fields\n",
    "\n",
    "There are already pre-extracted features provided.\n",
    " \n",
    "Three sets of features: a shape contiguous descriptor, an interior texture histogram, and a ﬁne-scale margin histogram. For each feature, a 64-attribute vector is given per leaf sample.\n",
    "\n",
    "| Column      | Description  |\n",
    "|-------------|---|\n",
    "|  id   | an anonymous id unique to an image  |\n",
    "|  margin_1, margin_2, margin_3, ..., margin_64     |  each of the 64 attribute vectors for the margin feature|\n",
    "| shape_1, shape_2, shape_3, ..., shape_64 | each of the 64 attribute vectors for the shape feature |\n",
    "| texture_1, texture_2, texture_3, ..., texture_64 | each of the 64 attribute vectors for the texture feature |\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "Submissions are evaluated using the multi-class logarithmic loss. Each image has been labeled with one true species. For each image, you must submit a set of predicted probabilities (one for every species). \n",
    "\n",
    "#### The dataset is from kaggle.com:   https://www.kaggle.com/c/leaf-classification/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>species</th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Acer_Opalus</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pterocarya_Stenoptera</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Quercus_Hartwissiana</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                species   margin1   margin2   margin3   margin4  \\\n",
       "0   1            Acer_Opalus  0.007812  0.023438  0.023438  0.003906   \n",
       "1   2  Pterocarya_Stenoptera  0.005859  0.000000  0.031250  0.015625   \n",
       "2   3   Quercus_Hartwissiana  0.005859  0.009766  0.019531  0.007812   \n",
       "\n",
       "    margin5   margin6   margin7  margin8    ...      texture55  texture56  \\\n",
       "0  0.011719  0.009766  0.027344      0.0    ...       0.007812        0.0   \n",
       "1  0.025391  0.001953  0.019531      0.0    ...       0.000977        0.0   \n",
       "2  0.003906  0.005859  0.068359      0.0    ...       0.154300        0.0   \n",
       "\n",
       "   texture57  texture58  texture59  texture60  texture61  texture62  \\\n",
       "0   0.002930   0.002930   0.035156        0.0        0.0   0.004883   \n",
       "1   0.000000   0.000977   0.023438        0.0        0.0   0.000977   \n",
       "2   0.005859   0.000977   0.007812        0.0        0.0   0.000000   \n",
       "\n",
       "   texture63  texture64  \n",
       "0   0.000000   0.025391  \n",
       "1   0.039062   0.022461  \n",
       "2   0.020508   0.002930  \n",
       "\n",
       "[3 rows x 194 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data=pd.read_csv('train.csv')\n",
    "test_data=pd.read_csv('test.csv')\n",
    "\n",
    "train_data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm for creating the classification probabilities (weights) for clusters\n",
    "\n",
    " 1. I am putting both labeled and unlabeled data together.\n",
    " 2. I am fitting it into clusters.\n",
    " 3. Then, for each cluster, I use the labeled entries to count how many species are bundled together.\n",
    "    - If the count is 1, then all the unlabeled data get's the same label as the labeled data.\n",
    "    - If there are more, then the probability is split by the counts of each labeled species. *Ex: 2 entries with species A, and 1 entry with species B -> prob(A)=66.7%, prob(B)=33.3%*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def getAllFeatures(data):\n",
    "    return data.drop('id', 1).drop('species', 1)\n",
    "\n",
    "def fit_model(X):\n",
    "    X=preprocessing.scale(X)\n",
    "    \n",
    "    model=KMeans(n_clusters=99, n_jobs=-1).fit(X)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_species_weights_for_clusters(species, labels, error):    \n",
    "    y=pd.DataFrame()\n",
    "    y['species']=species\n",
    "    y['cluster_id']=labels\n",
    "    y['amount']=np.ones(len(species))\n",
    "    \n",
    "    catalogue=y.pivot(columns='species', values='amount').fillna(0)\n",
    "    catalogue['cluster_id']=labels\n",
    "    catalogue=catalogue.groupby('cluster_id').sum()\n",
    "    \n",
    "    # to improve our score if we miss-classify \n",
    "    # we add a small probability to all the weights\n",
    "    catalogue=catalogue.replace(0,error)    \n",
    "\n",
    "    # we scale the probabilities to sum to 1 per cluster_id\n",
    "    c_sum=catalogue.sum(axis=1)      \n",
    "    weights=catalogue.apply(lambda x: x / c_sum)     \n",
    "    return weights\n",
    "    \n",
    "def getPredictions(model, weights, test_data):\n",
    "    predictions=pd.DataFrame()\n",
    "    predictions['id']=test_data['id']\n",
    "    predictions['cluster_id']=test_data['labels'] \n",
    "    \n",
    "    return pd.merge(predictions, weights, left_on='cluster_id', right_index=True\n",
    "                   ).drop('cluster_id', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# implementation of the multi-class logarithmic loss\n",
    "def score(predictions,y_test):\n",
    "    y=pd.DataFrame()\n",
    "    y['species']=y_test\n",
    "    y['amount']=np.ones(len(y_test))\n",
    "    catalogue=y.pivot(columns='species', values='amount').fillna(0)\n",
    "    \n",
    "    pred=predictions.drop('id', 1).replace(0, 10**-15).apply(lambda x: np.log(x))    \n",
    "    return pred.mul(catalogue).sum().sum() / len(pred) * -1\n",
    "        \n",
    "def predict_using_both_train_test_data(train_data, test_data, error):    \n",
    "    test_data['species']='-1'\n",
    "    all_data=train_data.append(test_data)    \n",
    "\n",
    "    model=fit_model( getAllFeatures(all_data))\n",
    "    all_data['labels']=model.labels_\n",
    "\n",
    "    train_index=all_data['species'] != '-1'\n",
    "    weights=create_species_weights_for_clusters(all_data[train_index]['species'],\n",
    "                                                all_data[train_index]['labels'],\n",
    "                                                error)\n",
    "\n",
    "    test_index=all_data['species'] == '-1'\n",
    "    predictions=getPredictions(model, weights, all_data[test_index].drop('species',1))\n",
    "\n",
    "    if(len(predictions) != len(test_data)):\n",
    "        print \"[WARNING] There are clusters without labelled data\"        \n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] There are clusters without labelled data\n",
      "0.480443989959\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def CV(error):\n",
    "    nr=10    \n",
    "    sc=0\n",
    "    kf = KFold(n_splits=nr)\n",
    "\n",
    "    for train_index, test_index in kf.split(train_data):\n",
    "        \n",
    "        predictions=predict_using_both_train_test_data(\n",
    "                                train_data.iloc[train_index], \n",
    "                                train_data.iloc[test_index].drop('species',1),\n",
    "                                error)        \n",
    "        new_score=score(predictions, train_data.iloc[test_index]['species'])\n",
    "        sc=sc+new_score\n",
    "    return sc/nr\n",
    "\n",
    "print str( CV(0.001) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# train on all the data\n",
    "predictions=predict_using_both_train_test_data( train_data, test_data, 0.001)\n",
    "\n",
    "predictions.to_csv(path_or_buf='classifications.csv', header=True, index=False)\n",
    "print 'Done.'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
