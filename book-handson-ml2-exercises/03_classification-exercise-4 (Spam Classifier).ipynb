{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-10 17:51:13 URL:https://spamassassin.apache.org/old/publiccorpus/20021010_spam.tar.bz2 [1192582/1192582] -> \"temp/20021010_spam.tar.bz2\" [1]\n",
      "2020-10-10 17:51:14 URL:https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2 [1677144/1677144] -> \"temp/20021010_easy_ham.tar.bz2\" [1]\n"
     ]
    }
   ],
   "source": [
    "!rm -fr temp && mkdir temp \n",
    "!wget -nv --directory-prefix=temp https://spamassassin.apache.org/old/publiccorpus/20021010_spam.tar.bz2\n",
    "!wget -nv --directory-prefix=temp https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2\n",
    "!cd temp && tar xjf 20021010_spam.tar.bz2 && tar xjf 20021010_easy_ham.tar.bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 12a1mailbot1@web.de  Thu Aug 22 13:17:22 2002\r\n",
      "Return-Path: <12a1mailbot1@web.de>\r\n",
      "Delivered-To: zzzz@localhost.example.com\r\n",
      "Received: from localhost (localhost [127.0.0.1])\r\n",
      "\tby phobos.labs.example.com (Postfix) with ESMTP id 136B943C32\r\n",
      "\tfor <zzzz@localhost>; Thu, 22 Aug 2002 08:17:21 -0400 (EDT)\r\n",
      "Received: from mail.webnote.net [193.120.211.219]\r\n",
      "\tby localhost with POP3 (fetchmail-5.9.0)\r\n",
      "\tfor zzzz@localhost (single-drop); Thu, 22 Aug 2002 13:17:21 +0100 (IST)\r\n",
      "Received: from dd_it7 ([210.97.77.167])\r\n"
     ]
    }
   ],
   "source": [
    "!head temp/spam/0001.bfc8d64d12b325ff385cca8d07b84288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import email, pandas as pd, numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, exists\n",
    "import codecs, re\n",
    "\n",
    "def read(filename):\n",
    "    try:\n",
    "        f = codecs.open(filename, encoding='utf-8', errors='strict')\n",
    "        return f.read()        \n",
    "    except UnicodeDecodeError:\n",
    "        return ''                \n",
    "    \n",
    "def read_input_data(pairs):\n",
    "    contents, labels = [], []\n",
    "    for folder, label in pairs:\n",
    "        for f in listdir(folder):\n",
    "            c = read(folder + '/' + f)\n",
    "            if c != '':\n",
    "                contents.append(c)\n",
    "                labels.append(label)\n",
    "    result, y = pd.DataFrame(), pd.DataFrame()\n",
    "    result['content'] = contents\n",
    "    y['label'] = labels\n",
    "    return (result, y)\n",
    "\n",
    "class FilterBodyOnly(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def _recurse_concat(a):\n",
    "        b = a.get_payload()\n",
    "        if isinstance(b, list):\n",
    "            result = ''\n",
    "            for part in b:\n",
    "                result += FilterBodyOnly._recurse_concat(part)\n",
    "        else:\n",
    "            result = b\n",
    "        return result\n",
    "    \n",
    "    def _get_body(X):\n",
    "        b = email.message_from_string(X)\n",
    "        return FilterBodyOnly._recurse_concat(b)\n",
    "                \n",
    "    def transform(self, X, y=None):\n",
    "        X['content'] = X['content'].apply(FilterBodyOnly._get_body)\n",
    "        return X\n",
    "    \n",
    "class EliminateUnusablewords(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def _remove_HTML_tags(text):\n",
    "        return re.sub('<[^<]+>', \" \", text)\n",
    "    \n",
    "    def _replace_special_chars(text):\n",
    "        return text.replace('\\t', ' ').\\\n",
    "                    replace('\\n', ' ').\\\n",
    "                    replace('.', ' ').\\\n",
    "                    replace(',', ' ')\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        X['content'] = X['content'].apply(EliminateUnusablewords._remove_HTML_tags)\n",
    "        X['content'] = X['content'].apply(EliminateUnusablewords._replace_special_chars)\n",
    "        return X\n",
    "    \n",
    "class SplitWords(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.words_dict={}\n",
    "\n",
    "    def _build_dictionary(self, X):\n",
    "        index=0\n",
    "        for row in X['content']:\n",
    "            for word in row.split(' '):\n",
    "                if word != '' and word not in self.words_dict:\n",
    "                        self.words_dict[word] = index\n",
    "                        index += 1\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self._build_dictionary(X)\n",
    "        return self\n",
    "            \n",
    "    def transform(self, X, y=None):\n",
    "        self._build_dictionary(X)\n",
    "        result = np.zeros((X['content'].shape[0], (len(self.words_dict))))        \n",
    "        for i, row in enumerate(X['content']):\n",
    "            for word in row.split(' '):\n",
    "                if word != '':\n",
    "                    result[i, self.words_dict[word]] += 1\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X, y = read_input_data(pairs=[('temp/spam', 1), \n",
    "                              ('temp/easy_ham', 0)\n",
    "                             ])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('filter_body', FilterBodyOnly()),\n",
    "    ('eliminate_unusable_words', EliminateUnusablewords()),\n",
    "    ('split_words', SplitWords()),\n",
    "])\n",
    "\n",
    "X = pipeline.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gpachitariu/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994720168954594"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = True_Positives / (True_Positives+False_Positives) = 1.0\n",
      "Recall = True_Positives / (True_Positives+False_Negatives) = 0.996415770609319\n"
     ]
    }
   ],
   "source": [
    "# recall & precision\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print('Precision = True_Positives / (True_Positives+False_Positives) = ', end='')\n",
    "print(precision_score(y_train, sgd_clf.predict(X_train)))\n",
    "\n",
    "print('Recall = True_Positives / (True_Positives+False_Negatives) = ', end='')\n",
    "print(recall_score(y_train, sgd_clf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = True_Positives / (True_Positives+False_Positives) = 0.968\n",
      "Recall = True_Positives / (True_Positives+False_Negatives) = 0.8705035971223022\n"
     ]
    }
   ],
   "source": [
    "print('Precision = True_Positives / (True_Positives+False_Positives) = ', end='')\n",
    "print(precision_score(y_test, sgd_clf.predict(X_test)))\n",
    "\n",
    "print('Recall = True_Positives / (True_Positives+False_Negatives) = ', end='')\n",
    "print(recall_score(y_test, sgd_clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
