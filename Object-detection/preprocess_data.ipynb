{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This module preprocesses the data to create the regression and classification labels used by the Region Proposing Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "SCALE = 600/18\n",
    "OUT_LEN = 17\n",
    "\n",
    "def create_anchors_map():\n",
    "    anchors_map = np.zeros((17, 17, 3, 3), dtype=[('y1', 'i4'),('x1', 'i4'), ('y2', 'i4'), ('x2', 'i4')])\n",
    "    for i in range(17):\n",
    "        for j in range(17):\n",
    "            for r, ratio in enumerate(((1, 1), (0.75, 1.5), (1.5, 0.75))):\n",
    "                for s, size in enumerate((128, 256, 512)):\n",
    "                    anchor_x_center = i * SCALE\n",
    "                    anchor_x1 = anchor_x_center - ratio[1] * size / 2\n",
    "                    anchor_x2 = anchor_x_center + ratio[1] * size / 2\n",
    "                    \n",
    "                    anchor_y_center = j * SCALE\n",
    "                    anchor_y1 = anchor_y_center - ratio[0] * size / 2\n",
    "                    anchor_y2 = anchor_y_center + ratio[0] * size / 2\n",
    "                        \n",
    "                    anchors_map[i][j][r][s] = (anchor_y1, anchor_x1, anchor_y2, anchor_x2)\n",
    "    return anchors_map\n",
    "                        \n",
    "anchors_map = create_anchors_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_extra(y1, x1, y2, x2):\n",
    "    center_x = (x1 + x2) // 2\n",
    "    center_y = (y1 + y2) // 2\n",
    "    width = x2 - x1\n",
    "    height = y2 - y1  \n",
    "    return center_x, center_y, width, height\n",
    "\n",
    "\"\"\"def get_all_anchors_deprecated():\n",
    "    for i in range(17):\n",
    "        for j in range(17):\n",
    "            for r, ratio in enumerate(((1, 1), (0.75, 1.5), (1.5, 0.75))):\n",
    "                for s, size in enumerate((128, 256, 512)):\n",
    "                    \n",
    "                    anchor_x1 = i * SCALE\n",
    "                    anchor_x2 = anchor_x1 + ratio[1] * size            \n",
    "                    \n",
    "                    anchor_y1 = j * SCALE\n",
    "                    anchor_y2 = anchor_y1 + ratio[0] * size\n",
    "                    \n",
    "                    yield anchor_y1, anchor_x1, anchor_y2, anchor_x2, i, j, r, s\n",
    "\"\"\"\n",
    "\n",
    "def anchor_and_distance_to_groundtruth(anchor_y1, anchor_x1, anchor_y2, anchor_x2, distance):\n",
    "    t_x, t_y, t_w, t_h  = distance\n",
    "    \n",
    "    anchor_center_x, anchor_center_y, anchor_width, anchor_height = get_box_extra(\n",
    "                                    anchor_y1, anchor_x1, anchor_y2, anchor_x2)\n",
    "    \n",
    "    groundtruth_center_x = anchor_center_x + t_x * anchor_width\n",
    "    groundtruth_center_y = anchor_center_y + t_y * anchor_height\n",
    "    groundtruth_width = anchor_width * np.e ** t_w\n",
    "    groundtruth_height = anchor_height * np.e ** t_h\n",
    "    \n",
    "    return groundtruth_center_x - groundtruth_width / 2, \\\n",
    "           groundtruth_center_y - groundtruth_height / 2, groundtruth_width, groundtruth_height    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groundtruth_x..y are single values\n",
    "# anchor x..y are (17,17) arrays\n",
    "def prepare_classification_values(groundtruth_y1, groundtruth_x1, groundtruth_y2, groundtruth_x2,\n",
    "                              anchor_y1, anchor_x1, anchor_y2, anchor_x2):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    ones = np.ones((OUT_LEN, OUT_LEN))\n",
    "    x1 = ones * np.maximum(groundtruth_x1, anchor_x1)\n",
    "    y1 = ones * np.maximum(groundtruth_y1, anchor_y1)\n",
    "    x2 = ones * np.minimum(groundtruth_x2, anchor_x2)\n",
    "    y2 = ones * np.minimum(groundtruth_y2, anchor_y2) \n",
    "    \n",
    "    intersection_area = np.maximum(0, x2 - x1) * np.maximum(0, y2 - y1)\n",
    "    \n",
    "    groundtruth_area = (groundtruth_x2 - groundtruth_x1) * (groundtruth_y2 - groundtruth_y1)\n",
    "    anchor_area = (anchor_x2 - anchor_x1) * (anchor_y2 - anchor_y1)\n",
    "    \n",
    "    iou = intersection_area / (groundtruth_area + anchor_area - intersection_area)    \n",
    "    return iou   \n",
    "\n",
    "def prepare_classification_values_test():\n",
    "    anchor_x1 = np.array([[1]])\n",
    "    anchor_y1 = np.array([[1]])\n",
    "    anchor_x2 = np.array([[3]])    \n",
    "    anchor_y2 = np.array([[3]])\n",
    "    \n",
    "    groundtruth_y1, groundtruth_x1, groundtruth_y2, groundtruth_x2 = [0, 0, 2, 2]\n",
    "    \n",
    "    tmp = prepare_classification_values(groundtruth_y1, groundtruth_x1, groundtruth_y2, groundtruth_x2,\n",
    "                                    anchor_y1, anchor_x1, anchor_y2, anchor_x2)\n",
    "    \n",
    "    assert -0.001 < tmp[0][0] - (1/7) < 0.001\n",
    "    \n",
    "def prepare_classification_values_test_adhoc():\n",
    "    anchor_x1 = np.array([[1]])\n",
    "    anchor_y1 = np.array([[1]])\n",
    "    anchor_x2 = np.array([[10]])    \n",
    "    anchor_y2 = np.array([[10]])\n",
    "    \n",
    "    groundtruth_y1, groundtruth_x1, groundtruth_y2, groundtruth_x2 = [1, 1, 3, 3]\n",
    "    \n",
    "    tmp = prepare_classification_values(groundtruth_y1, groundtruth_x1, groundtruth_y2, groundtruth_x2,\n",
    "                                    anchor_y1, anchor_x1, anchor_y2, anchor_x2)\n",
    "    \n",
    "    print(tmp)\n",
    "    \n",
    "prepare_classification_values_test()\n",
    "#prepare_classification_values_test_adhoc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overwrite_anchors_iou_closer_to_object(y_class, new_iou, pos):\n",
    "    for i in range(17):\n",
    "        for j in range(17):\n",
    "            # only overwrite the anchors that are closer to the current groundtruth truth object,\n",
    "            # or that haven't been initialized\n",
    "            if y_class[i, j, pos] == -1 or y_class[i, j, pos] < new_iou[i, j]:\n",
    "                y_class[i,j, pos] = new_iou[i, j]    \n",
    "\n",
    "def prepare_output_values(row_dict):\n",
    "    # output of last regression layer per image: (17, 17, 36) \n",
    "    # 17 anchors and 4 (dimensions) * 9 (scales & sizes)\n",
    "\n",
    "    y_regr = np.zeros((17,17,3,3,4)) + 100\n",
    "    y_class = np.zeros((17,17,9)) - 1\n",
    "    \n",
    "    for obj in row_dict['objects']['bbox']:\n",
    "        \n",
    "        groundtruth_y1, groundtruth_x1, groundtruth_y2, groundtruth_x2 = bbox_perc_to_pixels(obj)\n",
    "        groundtruth_center_x, groundtruth_center_y, groundtruth_width, groundtruth_height = get_box_extra(\n",
    "                                            groundtruth_y1, groundtruth_x1, groundtruth_y2, groundtruth_x2)\n",
    "        \n",
    "        anchor_center_x = (anchors_map['x1'] + anchors_map['x2']) // 2\n",
    "        anchor_center_y = (anchors_map['y1'] + anchors_map['y2']) // 2\n",
    "        anchor_width = anchors_map['x2'] - anchors_map['x1']\n",
    "        anchor_height = anchors_map['y2'] - anchors_map['y1']\n",
    "\n",
    "        current = np.zeros(y_regr.shape)\n",
    "        current[:,:,:,:,0] = (groundtruth_center_x - anchor_center_x) / anchor_width # t_x\n",
    "        current[:,:,:,:,1] = (groundtruth_center_y - anchor_center_y) / anchor_height # t_y\n",
    "        current[:,:,:,:,2] = np.log(groundtruth_width / anchor_width) # t_w\n",
    "        current[:,:,:,:,3] = np.log(groundtruth_height / anchor_height) # t_h\n",
    "        \n",
    "        # overwrite anchors distances closer to ground-truth object.\n",
    "        # cloer = minimum sum of (t_x, t_y, t_w, t_h)\n",
    "        current_sum = np.sum(np.abs(current), axis = -1)\n",
    "        y_regr_sum = np.sum(np.abs(y_regr), axis = -1)        \n",
    "        y_regr[current_sum < y_regr_sum] = current[current_sum < y_regr_sum]\n",
    "        \n",
    "        \n",
    "        \n",
    "    #for anchor_y1, anchor_x1, anchor_y2, anchor_x2, _, _, r, s in get_all_anchors():                \n",
    "            #for obj in row_dict['objects']['bbox']:\n",
    "                #overwrite_anchors_distances_closer_to_object(y_regr, curr_dist, r*3+s)\n",
    "                #iou=prepare_classification_values(groundtruth_y1, groundtruth_x1, groundtruth_y2, groundtruth_x2,\n",
    "                #                                  anchor_y1, anchor_x1, anchor_y2, anchor_x2)\n",
    "                #overwrite_anchors_iou_closer_to_object(y_class, iou, r*3+s)\n",
    "                                \n",
    "    return y_regr, y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MIN = regression_values_dataset.min()\n",
    "#regression_values_dataset += (0-MIN)\n",
    "\n",
    "#NORMALIZED_VALUE = regression_values_dataset.max()\n",
    "#regression_values_dataset = regression_values_dataset / NORMALIZED_VALUE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
